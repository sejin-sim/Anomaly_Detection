{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-SVDD_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+OwfwEarfbTw/YU2BgI1O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1114c6835470406bb09a1b8539d46d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6bc930286a16430c922506cdc60e12e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c070d5bc59dc4648b5cae1b9ad48b6ce",
              "IPY_MODEL_bd84e70bec8a4147865dd9a170c0f003"
            ]
          }
        },
        "6bc930286a16430c922506cdc60e12e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c070d5bc59dc4648b5cae1b9ad48b6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af9d9400f46b41a79e4302b0c931ee66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19c3059ff266400885da65d25bd941b1"
          }
        },
        "bd84e70bec8a4147865dd9a170c0f003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62dca97096424844ab187300054dbd21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [01:01&lt;00:00, 162468.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1eaf287f190348368c0b656b1686d0a4"
          }
        },
        "af9d9400f46b41a79e4302b0c931ee66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19c3059ff266400885da65d25bd941b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62dca97096424844ab187300054dbd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1eaf287f190348368c0b656b1686d0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9a7024ceb1e4b8f81c517901341f2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_27068eb1f0f444b2a2d557a16880821d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff4f557257a14035b115724103a19188",
              "IPY_MODEL_c404e9e2f5f24821884e1e39dee0d548"
            ]
          }
        },
        "27068eb1f0f444b2a2d557a16880821d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff4f557257a14035b115724103a19188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_616d213f755c49f883c79d408183904e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61c1463bc0bd4798b9cfd729cdf4b426"
          }
        },
        "c404e9e2f5f24821884e1e39dee0d548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ddc179b2345f4e83a1cdc93c1629d714",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [01:00&lt;00:00, 493.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09d310167c514776b441d3831a5c77cc"
          }
        },
        "616d213f755c49f883c79d408183904e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61c1463bc0bd4798b9cfd729cdf4b426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddc179b2345f4e83a1cdc93c1629d714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09d310167c514776b441d3831a5c77cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70f5c50d35df4d8a9983fd8b9ee53264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_37342f941486428eaea59db462da4cf5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2f0c60635094118a4f236f0f6071ddc",
              "IPY_MODEL_39e2a1db9456419390d0f8158a0602f3"
            ]
          }
        },
        "37342f941486428eaea59db462da4cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2f0c60635094118a4f236f0f6071ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d7644221761245e999fc2f06db52005a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_605d6629b3324ac4ae2ee0b036362860"
          }
        },
        "39e2a1db9456419390d0f8158a0602f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_934289b410234be5b42566b858fbdfbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 2165840.19it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57d6a00f566e4e9f95ed9a9834a3365f"
          }
        },
        "d7644221761245e999fc2f06db52005a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "605d6629b3324ac4ae2ee0b036362860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "934289b410234be5b42566b858fbdfbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57d6a00f566e4e9f95ed9a9834a3365f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e17fe9b2c6374c86a250ab040437627e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec598c5b04594486941627d682b69ccf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76f62ac4779347b5a69e633f1cff3a0b",
              "IPY_MODEL_d565855aecd44377a0bba54b1c99eb08"
            ]
          }
        },
        "ec598c5b04594486941627d682b69ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76f62ac4779347b5a69e633f1cff3a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5467560330fb4e69bd073447c3d19d17",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af6d5fef26d34880b04c41c3f2e2e8e0"
          }
        },
        "d565855aecd44377a0bba54b1c99eb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9bbfd9401a22438da3180f1a8bb0b422",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 17037.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ed3088f31944991a37272b73e3cbbfc"
          }
        },
        "5467560330fb4e69bd073447c3d19d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af6d5fef26d34880b04c41c3f2e2e8e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bbfd9401a22438da3180f1a8bb0b422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ed3088f31944991a37272b73e3cbbfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejin-sim/Anomaly_Detection/blob/main/Deep_SVDD_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eOrsV7wDWU6"
      },
      "source": [
        "- 출처 : https://github.com/mperezcarrasco/PyTorch-Deep-SVDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bMuKWonETur",
        "outputId": "6703c3b1-cf3d-455d-96e6-d4e6cae47154"
      },
      "source": [
        "! pip install barbar\n",
        "! mkdir /content/weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting barbar\n",
            "  Downloading https://files.pythonhosted.org/packages/48/1f/9b69ce144f484cfa00feb09fa752139658961de6303ea592487738d0b53c/barbar-0.2.1-py3-none-any.whl\n",
            "Installing collected packages: barbar\n",
            "Successfully installed barbar-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXIFYOpeEY1F"
      },
      "source": [
        "# utils.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1 and classname != 'Conv':\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"Linear\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "\n",
        "# 샘플당 모든 pixel에 대한 평균을 구함\n",
        "def global_contrast_normalization(x):\n",
        "    \"\"\"Apply global contrast normalization to tensor. \"\"\"\n",
        "    mean = torch.mean(x)  # mean over all features (pixels) per sample\n",
        "    x -= mean\n",
        "    x_scale = torch.mean(torch.abs(x))\n",
        "    x /= x_scale\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_GFM9hwFAkz"
      },
      "source": [
        "# model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class network(nn.Module):\n",
        "    def __init__(self, z_dim=32):\n",
        "        super(network, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
        "        self.conv2 = nn.Conv2d(8, 4, 5, bias=False, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
        "        self.fc1 = nn.Linear(4 * 7 * 7, z_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(F.leaky_relu(self.bn1(x)))\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(F.leaky_relu(self.bn2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc1(x)\n",
        "\n",
        "# data를 새롭게 representation하기 위한 AutoEncoder\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self, z_dim=32):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
        "        self.conv2 = nn.Conv2d(8, 4, 5, bias=False, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
        "        self.fc1 = nn.Linear(4 * 7 * 7, z_dim, bias=False)\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(2, 4, 5, bias=False, padding=2)\n",
        "        self.bn3 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
        "        self.deconv2 = nn.ConvTranspose2d(4, 8, 5, bias=False, padding=3)\n",
        "        self.bn4 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
        "        self.deconv3 = nn.ConvTranspose2d(8, 1, 5, bias=False, padding=2)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(F.leaky_relu(self.bn1(x)))\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(F.leaky_relu(self.bn2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc1(x)\n",
        "   \n",
        "    def decode(self, x):\n",
        "        x = x.view(x.size(0), int(self.z_dim / 16), 4, 4)\n",
        "        x = F.interpolate(F.leaky_relu(x), scale_factor=2)\n",
        "        x = self.deconv1(x)\n",
        "        x = F.interpolate(F.leaky_relu(self.bn3(x)), scale_factor=2)\n",
        "        x = self.deconv2(x)\n",
        "        x = F.interpolate(F.leaky_relu(self.bn4(x)), scale_factor=2)\n",
        "        x = self.deconv3(x)\n",
        "        return torch.sigmoid(x)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        x_hat = self.decode(z)\n",
        "        return x_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFNiXYF2EmPs"
      },
      "source": [
        "# train.py\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from barbar import Bar\n",
        "\n",
        "class TrainerDeepSVDD:\n",
        "    def __init__(self, args, data, device):\n",
        "        self.args = args\n",
        "        self.train_loader, self.test_loader = data\n",
        "        self.device = device\n",
        "    \n",
        "\n",
        "    def pretrain(self):\n",
        "        # Deep SVDD에 적용할 가중치 W를 학습하기 위해 autoencoder를 학습함\n",
        "        ae = autoencoder(self.args.latent_dim).to(self.device)\n",
        "        ae.apply(weights_init_normal)\n",
        "        optimizer = optim.Adam(ae.parameters(), lr=self.args.lr_ae,\n",
        "                               weight_decay=self.args.weight_decay_ae)\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
        "                    milestones=self.args.lr_milestones, gamma=0.1)\n",
        "        \n",
        "        ae.train()\n",
        "        for epoch in range(self.args.num_epochs_ae):\n",
        "            total_loss = 0\n",
        "            for x, _ in Bar(self.train_loader):\n",
        "                x = x.float().to(self.device)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                x_hat = ae(x)\n",
        "                # 재구축 오차를 최소화하는 방향으로 학습함\n",
        "                # AE 모델을 통해 그 데이터를 잘 표현할 수 있는 common features를 찾는 것이 목표임\n",
        "                reconst_loss = torch.mean(torch.sum((x_hat - x) ** 2, dim=tuple(range(1, x_hat.dim()))))\n",
        "                reconst_loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                total_loss += reconst_loss.item()\n",
        "            scheduler.step()\n",
        "            print('Pretraining Autoencoder... Epoch: {}, Loss: {:.3f}'.format(\n",
        "                   epoch, total_loss/len(self.train_loader)))\n",
        "        self.save_weights_for_DeepSVDD(ae, self.train_loader) \n",
        "    \n",
        "\n",
        "    def save_weights_for_DeepSVDD(self, model, dataloader):\n",
        "        \"\"\"Initialize Deep SVDD weights using the encoder weights of the pretrained autoencoder.\"\"\"\n",
        "        c = self.set_c(model, dataloader)\n",
        "        net = network(self.args.latent_dim).to(self.device)\n",
        "        state_dict = model.state_dict()\n",
        "        net.load_state_dict(state_dict, strict=False)\n",
        "        torch.save({'center': c.cpu().data.numpy().tolist(),\n",
        "                    'net_dict': net.state_dict()}, '/content/weights/pretrained_parameters.pth')\n",
        "    \n",
        "\n",
        "    def set_c(self, model, dataloader, eps=0.1):\n",
        "        \"\"\"Initializing the center for the hypersphere\"\"\"\n",
        "        model.eval()\n",
        "        z_ = []\n",
        "        with torch.no_grad():\n",
        "            for x, _ in dataloader:\n",
        "                x = x.float().to(self.device)\n",
        "                z = model.encode(x)\n",
        "                z_.append(z.detach())\n",
        "        z_ = torch.cat(z_)\n",
        "        c = torch.mean(z_, dim=0)\n",
        "        c[(abs(c) < eps) & (c < 0)] = -eps\n",
        "        c[(abs(c) < eps) & (c > 0)] = eps\n",
        "        return c\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Training the Deep SVDD model\"\"\"\n",
        "        net = network().to(self.device)\n",
        "        \n",
        "        if self.args.pretrain==True:\n",
        "            state_dict = torch.load('/content/weights/pretrained_parameters.pth')\n",
        "            net.load_state_dict(state_dict['net_dict'])\n",
        "            c = torch.Tensor(state_dict['center']).to(self.device)\n",
        "        else:\n",
        "            net.apply(weights_init_normal)\n",
        "            c = torch.randn(self.args.latent_dim).to(self.device)\n",
        "        \n",
        "        optimizer = optim.Adam(net.parameters(), lr=self.args.lr,\n",
        "                               weight_decay=self.args.weight_decay)\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
        "                    milestones=self.args.lr_milestones, gamma=0.1)\n",
        "\n",
        "        net.train()\n",
        "        for epoch in range(self.args.num_epochs):\n",
        "            total_loss = 0\n",
        "            for x, _ in Bar(self.train_loader):\n",
        "                x = x.float().to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                z = net(x)\n",
        "                loss = torch.mean(torch.sum((z - c) ** 2, dim=1))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "            scheduler.step()\n",
        "            print('Training Deep SVDD... Epoch: {}, Loss: {:.3f}'.format(\n",
        "                   epoch, total_loss/len(self.train_loader)))\n",
        "        self.net = net\n",
        "        self.c = c\n",
        "                \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrsCCkl3E4SO"
      },
      "source": [
        "# we used the precomputed min_max values from the original implementation: \n",
        "# https://github.com/lukasruff/Deep-SVDD-PyTorch/blob/1901612d595e23675fb75c4ebb563dd0ffebc21e/src/datasets/mnist.py\n",
        "# process.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class MNIST_loader(data.Dataset):\n",
        "    \"\"\"This class is needed to processing batches for the dataloader.\"\"\"\n",
        "    def __init__(self, data, target, transform):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"return transformed items.\"\"\"\n",
        "        x = self.data[index]pretrain\n",
        "        y = self.target[index]\n",
        "        if self.transform:\n",
        "            x = Image.fromarray(x.numpy(), mode='L')\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"number of samples.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def get_mnist(args, data_dir='./data/mnist/'):\n",
        "    \"\"\"get dataloders\"\"\"\n",
        "    # min, max values for each class after applying GCN (as the original implementation)\n",
        "    min_max = [(-0.8826567065619495, 9.001545489292527),\n",
        "                (-0.6661464580883915, 20.108062262467364),\n",
        "                (-0.7820454743183202, 11.665100841080346),\n",
        "                (-0.7645772083211267, 12.895051191467457),\n",
        "                (-0.7253923114302238, 12.683235701611533),\n",
        "                (-0.7698501867861425, 13.103278415430502),\n",
        "                (-0.778418217980696, 10.457837397569108),\n",
        "                (-0.7129780970522351, 12.057777597673047),\n",
        "                (-0.8280402650205075, 10.581538445782988),\n",
        "                (-0.7369959242164307, 10.697039838804978)]\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Lambda(lambda x: global_contrast_normalization(x)),\n",
        "                                    transforms.Normalize([min_max[args.normal_class][0]],\n",
        "                                                         [min_max[args.normal_class][1] \\\n",
        "                                                         -min_max[args.normal_class][0]])])\n",
        "    train = datasets.MNIST(root=data_dir, train=True, download=True)\n",
        "    test = datasets.MNIST(root=data_dir, train=False, download=True)\n",
        "\n",
        "    x_train = train.data\n",
        "    y_train = train.targets\n",
        "\n",
        "    # 학습에 사용하는 데이터에는 normal data만 포함함\n",
        "    x_train = x_train[np.where(y_train==args.normal_class)]\n",
        "    y_train = y_train[np.where(y_train==args.normal_class)]\n",
        "\n",
        "    # 테스트를 위해서는 normal, anomal이 섞여 있음                                \n",
        "    data_train = MNIST_loader(x_train, y_train, transform)\n",
        "    dataloader_train = DataLoader(data_train, batch_size=args.batch_size, \n",
        "                                  shuffle=True, num_workers=0)\n",
        "    \n",
        "    x_test = test.data\n",
        "    y_test = test.targets\n",
        "    y_test = np.where(y_test==args.normal_class, 0, 1)\n",
        "    data_test = MNIST_loader(x_test, y_test, transform)\n",
        "    dataloader_test = DataLoader(data_test, batch_size=args.batch_size, \n",
        "                                  shuffle=True, num_workers=0)\n",
        "    return dataloader_train, dataloader_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1114c6835470406bb09a1b8539d46d83",
            "6bc930286a16430c922506cdc60e12e3",
            "c070d5bc59dc4648b5cae1b9ad48b6ce",
            "bd84e70bec8a4147865dd9a170c0f003",
            "af9d9400f46b41a79e4302b0c931ee66",
            "19c3059ff266400885da65d25bd941b1",
            "62dca97096424844ab187300054dbd21",
            "1eaf287f190348368c0b656b1686d0a4",
            "e9a7024ceb1e4b8f81c517901341f2f7",
            "27068eb1f0f444b2a2d557a16880821d",
            "ff4f557257a14035b115724103a19188",
            "c404e9e2f5f24821884e1e39dee0d548",
            "616d213f755c49f883c79d408183904e",
            "61c1463bc0bd4798b9cfd729cdf4b426",
            "ddc179b2345f4e83a1cdc93c1629d714",
            "09d310167c514776b441d3831a5c77cc",
            "70f5c50d35df4d8a9983fd8b9ee53264",
            "37342f941486428eaea59db462da4cf5",
            "f2f0c60635094118a4f236f0f6071ddc",
            "39e2a1db9456419390d0f8158a0602f3",
            "d7644221761245e999fc2f06db52005a",
            "605d6629b3324ac4ae2ee0b036362860",
            "934289b410234be5b42566b858fbdfbc",
            "57d6a00f566e4e9f95ed9a9834a3365f",
            "e17fe9b2c6374c86a250ab040437627e",
            "ec598c5b04594486941627d682b69ccf",
            "76f62ac4779347b5a69e633f1cff3a0b",
            "d565855aecd44377a0bba54b1c99eb08",
            "5467560330fb4e69bd073447c3d19d17",
            "af6d5fef26d34880b04c41c3f2e2e8e0",
            "9bbfd9401a22438da3180f1a8bb0b422",
            "3ed3088f31944991a37272b73e3cbbfc"
          ]
        },
        "id": "A-6BMwpLFd5F",
        "outputId": "9bf6f01b-85f0-4974-df2f-9383fd521c6e"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 파라미터 지정\n",
        "class Args:\n",
        "    num_epochs=150\n",
        "    num_epochs_ae=150\n",
        "    patience=50\n",
        "    lr=1e-4\n",
        "    weight_decay=0.5e-6\n",
        "    weight_decay_ae=0.5e-3\n",
        "    lr_ae=1e-4\n",
        "    lr_milestones=[50]\n",
        "    batch_size=200\n",
        "    pretrain=True\n",
        "    latent_dim=32\n",
        "    normal_class=1\n",
        "    \n",
        "    \n",
        "args = Args()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = get_mnist(args)\n",
        "\n",
        "deep_SVDD = TrainerDeepSVDD(args, data, device)\n",
        "\n",
        "if args.pretrain:\n",
        "    deep_SVDD.pretrain()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1114c6835470406bb09a1b8539d46d83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9a7024ceb1e4b8f81c517901341f2f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70f5c50d35df4d8a9983fd8b9ee53264",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e17fe9b2c6374c86a250ab040437627e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6742/6742: [===============================>] - ETA 0.2s\n",
            "Pretraining Autoencoder... Epoch: 0, Loss: 139.275\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 1, Loss: 99.646\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 2, Loss: 71.086\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 3, Loss: 51.822\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 4, Loss: 39.024\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 5, Loss: 30.387\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 6, Loss: 24.439\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 7, Loss: 20.177\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 8, Loss: 17.043\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 9, Loss: 14.678\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 10, Loss: 12.853\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 11, Loss: 11.407\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 12, Loss: 10.243\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 13, Loss: 9.282\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 14, Loss: 8.475\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 15, Loss: 7.793\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 16, Loss: 7.205\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 17, Loss: 6.688\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 18, Loss: 6.238\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 19, Loss: 5.842\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 20, Loss: 5.490\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 21, Loss: 5.178\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 22, Loss: 4.894\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 23, Loss: 4.639\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 24, Loss: 4.410\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 25, Loss: 4.204\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 26, Loss: 4.015\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 27, Loss: 3.843\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 28, Loss: 3.683\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 29, Loss: 3.532\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 30, Loss: 3.390\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 31, Loss: 3.261\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 32, Loss: 3.141\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 33, Loss: 3.028\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 34, Loss: 2.920\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 35, Loss: 2.821\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 36, Loss: 2.729\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 37, Loss: 2.643\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 38, Loss: 2.563\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 39, Loss: 2.487\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 40, Loss: 2.415\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 41, Loss: 2.350\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 42, Loss: 2.288\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 43, Loss: 2.228\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 44, Loss: 2.172\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 45, Loss: 2.121\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 46, Loss: 2.072\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 47, Loss: 2.024\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 48, Loss: 1.979\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 49, Loss: 1.938\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 50, Loss: 1.913\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 51, Loss: 1.909\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 52, Loss: 1.905\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 53, Loss: 1.901\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 54, Loss: 1.896\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 55, Loss: 1.892\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 56, Loss: 1.888\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 57, Loss: 1.884\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 58, Loss: 1.879\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 59, Loss: 1.875\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 60, Loss: 1.869\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 61, Loss: 1.865\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 62, Loss: 1.860\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 63, Loss: 1.855\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 64, Loss: 1.850\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 65, Loss: 1.846\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 66, Loss: 1.842\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 67, Loss: 1.836\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 68, Loss: 1.831\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 69, Loss: 1.826\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 70, Loss: 1.822\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 71, Loss: 1.816\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 72, Loss: 1.810\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 73, Loss: 1.805\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 74, Loss: 1.799\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 75, Loss: 1.794\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 76, Loss: 1.790\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 77, Loss: 1.784\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 78, Loss: 1.779\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 79, Loss: 1.774\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 80, Loss: 1.766\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 81, Loss: 1.761\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 82, Loss: 1.756\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 83, Loss: 1.750\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 84, Loss: 1.743\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 85, Loss: 1.738\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 86, Loss: 1.733\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 87, Loss: 1.725\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 88, Loss: 1.720\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 89, Loss: 1.714\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 90, Loss: 1.708\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 91, Loss: 1.701\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 92, Loss: 1.695\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 93, Loss: 1.689\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 94, Loss: 1.682\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 95, Loss: 1.677\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 96, Loss: 1.671\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 97, Loss: 1.663\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 98, Loss: 1.657\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 99, Loss: 1.651\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 100, Loss: 1.643\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 101, Loss: 1.637\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 102, Loss: 1.629\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 103, Loss: 1.623\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 104, Loss: 1.615\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 105, Loss: 1.609\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 106, Loss: 1.602\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 107, Loss: 1.597\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 108, Loss: 1.590\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 109, Loss: 1.581\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 110, Loss: 1.575\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 111, Loss: 1.568\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 112, Loss: 1.562\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 113, Loss: 1.553\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 114, Loss: 1.548\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 115, Loss: 1.541\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 116, Loss: 1.534\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 117, Loss: 1.526\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 118, Loss: 1.522\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 119, Loss: 1.514\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 120, Loss: 1.508\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 121, Loss: 1.500\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 122, Loss: 1.494\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 123, Loss: 1.488\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 124, Loss: 1.481\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 125, Loss: 1.474\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 126, Loss: 1.468\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 127, Loss: 1.461\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 128, Loss: 1.455\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 129, Loss: 1.448\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 130, Loss: 1.441\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 131, Loss: 1.433\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 132, Loss: 1.428\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 133, Loss: 1.421\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 134, Loss: 1.416\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 135, Loss: 1.408\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 136, Loss: 1.402\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 137, Loss: 1.396\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Pretraining Autoencoder... Epoch: 138, Loss: 1.390\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 139, Loss: 1.383\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 140, Loss: 1.376\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 141, Loss: 1.371\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 142, Loss: 1.363\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 143, Loss: 1.357\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 144, Loss: 1.352\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 145, Loss: 1.345\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 146, Loss: 1.339\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 147, Loss: 1.332\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 148, Loss: 1.326\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Pretraining Autoencoder... Epoch: 149, Loss: 1.320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9SLhsV2F4cJ",
        "outputId": "0db47434-22b4-4e9a-c192-c578d6febb80"
      },
      "source": [
        "deep_SVDD.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 0, Loss: 3.808\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 1, Loss: 1.768\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 2, Loss: 0.634\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 3, Loss: 0.222\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 4, Loss: 0.131\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 5, Loss: 0.098\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 6, Loss: 0.079\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 7, Loss: 0.067\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 8, Loss: 0.058\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 9, Loss: 0.052\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 10, Loss: 0.046\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 11, Loss: 0.042\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 12, Loss: 0.039\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 13, Loss: 0.036\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 14, Loss: 0.034\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 15, Loss: 0.032\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 16, Loss: 0.030\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 17, Loss: 0.028\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 18, Loss: 0.027\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 19, Loss: 0.026\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 20, Loss: 0.024\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 21, Loss: 0.023\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 22, Loss: 0.023\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 23, Loss: 0.021\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 24, Loss: 0.021\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 25, Loss: 0.020\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 26, Loss: 0.019\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 27, Loss: 0.018\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 28, Loss: 0.018\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 29, Loss: 0.017\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 30, Loss: 0.017\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 31, Loss: 0.016\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 32, Loss: 0.016\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 33, Loss: 0.015\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 34, Loss: 0.014\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 35, Loss: 0.014\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 36, Loss: 0.014\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 37, Loss: 0.014\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 38, Loss: 0.013\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 39, Loss: 0.013\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 40, Loss: 0.012\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 41, Loss: 0.012\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 42, Loss: 0.012\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 43, Loss: 0.011\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 44, Loss: 0.011\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 45, Loss: 0.011\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 46, Loss: 0.010\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 47, Loss: 0.010\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 48, Loss: 0.010\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 49, Loss: 0.010\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 50, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 51, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 52, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 53, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 54, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 55, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 56, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 57, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 58, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 59, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 60, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 61, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 62, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 63, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 64, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 65, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 66, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 67, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 68, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 69, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 70, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 71, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 72, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 73, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 74, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 75, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 76, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 77, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 78, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 79, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 80, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 81, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 82, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 83, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 84, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 85, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 86, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 87, Loss: 0.009\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 88, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 89, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 90, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 91, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 92, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 93, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 94, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 95, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 96, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 97, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 98, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 99, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 100, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 101, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 102, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 103, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 104, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 105, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 106, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 107, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 108, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 109, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 110, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 111, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 112, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 113, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 114, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 115, Loss: 0.008\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 116, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 117, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 118, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 119, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 120, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 121, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 122, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 123, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 124, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 125, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 126, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 127, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 128, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 129, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 130, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 131, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 132, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 133, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 134, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 135, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 136, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 137, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 138, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.0s\n",
            "Training Deep SVDD... Epoch: 139, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 140, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 141, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 142, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 143, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 144, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 145, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 146, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 147, Loss: 0.007\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 148, Loss: 0.006\n",
            "6742/6742: [===============================>] - ETA 0.1s\n",
            "Training Deep SVDD... Epoch: 149, Loss: 0.007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdPCZdq2F8wi"
      },
      "source": [
        "# test.py\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def eval(net, c, dataloader, device):\n",
        "    \"\"\"Testing the Deep SVDD model\"\"\"\n",
        "\n",
        "    scores = []\n",
        "    labels = []\n",
        "    net.eval()\n",
        "    print('Testing...')\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x = x.float().to(device)\n",
        "            z = net(x)\n",
        "            score = torch.sum((z - c) ** 2, dim=1)\n",
        "\n",
        "            scores.append(score.detach().cpu())\n",
        "            labels.append(y.cpu())\n",
        "    labels, scores = torch.cat(labels).numpy(), torch.cat(scores).numpy()\n",
        "    print('ROC AUC score: {:.2f}'.format(roc_auc_score(labels, scores)*100))\n",
        "    return labels, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKBMKK0dF7gC",
        "outputId": "d2b7bb05-5f54-48f8-87b0-05373112b0b0"
      },
      "source": [
        "labels, scores = eval(deep_SVDD.net, deep_SVDD.c, data[1], device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing...\n",
            "ROC AUC score: 99.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "HbZxlmQ3GBFs",
        "outputId": "f94cd0cc-6f18-44e9-9bbc-20b606b47ac4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "\n",
        "scores_in = scores[np.where(labels==0)[0]]\n",
        "scores_out = scores[np.where(labels==1)[0]]\n",
        "\n",
        "\n",
        "in_ = pd.DataFrame(scores_in, columns=['Inlier'])\n",
        "out_ = pd.DataFrame(scores_out, columns=['Outlier'])\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "in_.plot.kde(ax=ax, legend=True, title='Outliers vs Inliers (Deep SVDD)')\n",
        "out_.plot.kde(ax=ax, legend=True)\n",
        "plt.xlim(-0.05, 0.08)\n",
        "ax.grid(axis='x')\n",
        "ax.grid(axis='y')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}